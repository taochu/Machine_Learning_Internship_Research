{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, Flatten, Lambda\n",
    "from keras.layers import Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "K.get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "import sys\n",
    "sys.path.append('../util/')\n",
    "from util import plotProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000,-1)\n",
    "X_test = X_test.reshape(10000,-1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch = 128\n",
    "latent_dim = 2\n",
    "inter_dim1 = 400\n",
    "# inter_dim2 = 128\n",
    "# inter_dim3 = 64\n",
    "# inter_dim4 = 10\n",
    "optimizer = 'adam'\n",
    "rate_recon = 0.9999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean,z_log_var=args\n",
    "    epsilon=K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0,stddev=1)\n",
    "    return z_mean+K.exp(z_log_var/2)*epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossVAE(z_mean, z_sigma_log):\n",
    "    def loss(tensor_input, tensor_decode):\n",
    "        loss_recon =  metrics.binary_crossentropy(K.flatten(tensor_input), K.flatten(tensor_decode))\n",
    "        loss_KL = - 0.5 * K.sum(1 + z_sigma_log - K.square(z_mean) - K.exp(z_sigma_log), axis=-1)\n",
    "        return rate_recon*loss_recon + (1-rate_recon)*loss_KL\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 802       \n",
      "=================================================================\n",
      "Total params: 314,802\n",
      "Trainable params: 314,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs=Input(shape = (X_train.shape[1],))\n",
    "x = inputs\n",
    "x = Dense(inter_dim1,activation='relu')(x)\n",
    "# x = Dense(inter_dim2,activation='relu')(x)\n",
    "# x = Dense(inter_dim3,activation='relu')(x)\n",
    "# x = Dense(inter_dim4,activation='relu')(x)\n",
    "z_mean=Dense(latent_dim,activation='linear')(x)\n",
    "z_log_var=Dense(latent_dim,activation='linear')(x)\n",
    "encoder = Model(inputs,z_mean,name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 400)               1200      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 784)               314384    \n",
      "=================================================================\n",
      "Total params: 315,584\n",
      "Trainable params: 315,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "z=Lambda(sampling,output_shape=(latent_dim,))([z_mean,z_log_var])\n",
    "latent=Input(shape=(latent_dim,))\n",
    "# x=Dense(inter_dim4,activation='relu')(latent)\n",
    "# x=Dense(inter_dim3,activation='relu')(x)\n",
    "# x=Dense(inter_dim2,activation='relu')(latent)\n",
    "x=Dense(inter_dim1,activation='relu')(latent)\n",
    "x=Dense(X_train.shape[1],activation='sigmoid')(x)\n",
    "decoder=Model(latent,x)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2458 - val_loss: 0.2151\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2099 - val_loss: 0.2046\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2017 - val_loss: 0.1990\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1973 - val_loss: 0.1958\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1942 - val_loss: 0.1931\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1918 - val_loss: 0.1912\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1898 - val_loss: 0.1894\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1881 - val_loss: 0.1879\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1868 - val_loss: 0.1869\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1856 - val_loss: 0.1863\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1847 - val_loss: 0.1854\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1838 - val_loss: 0.1847\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1830 - val_loss: 0.1840\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1823 - val_loss: 0.1837\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1816 - val_loss: 0.1829\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1810 - val_loss: 0.1828\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1805 - val_loss: 0.1822\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1800 - val_loss: 0.1818\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1795 - val_loss: 0.1818\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1791 - val_loss: 0.1812\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1786 - val_loss: 0.1811\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1782 - val_loss: 0.1808\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1778 - val_loss: 0.1807\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1775 - val_loss: 0.1805\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1772 - val_loss: 0.1803\n",
      "Epoch 26/100\n",
      "19968/60000 [========>.....................] - ETA: 1s - loss: 0.1766"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(inputs,decoder(z))\n",
    "autoencoder.compile(optimizer = optimizer,loss = lossVAE(z_mean,z_log_var))\n",
    "es_cb = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1, mode = 'auto')\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                epochs = epochs,\n",
    "                batch_size = batch,\n",
    "                shuffle = True,\n",
    "                callbacks = [es_cb],\n",
    "                validation_data = (X_test,X_test))\n",
    "plotProgress(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = encoder.predict(X_test)\n",
    "cmap = ['cyan','black','orange','red','blue','lime','azure','wheat','salmon','navy']\n",
    "fig,ax = plt.subplots(figsize = (10,8))\n",
    "for i in range(10):\n",
    "    ax.scatter(pred[y_test == i,0],pred[y_test == i,1],\n",
    "               edgecolors = 'black',\n",
    "               c = cmap[i],\n",
    "               label = str(i),\n",
    "               s=50)\n",
    "    ax.annotate(str(i),(pred[y_test == i,0].mean(),pred[y_test == i,1].mean()),\n",
    "               bbox = dict(boxstyle = 'round', fc = 'w'))\n",
    "plt.legend()\n",
    "plt.savefig('images/clusters_0.9999999.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get decoded digits\n",
    "reconstructed = decoder.predict(pred)\n",
    "# plot decoded\n",
    "n = 10\n",
    "row = 12\n",
    "fig = plt.figure(figsize = (20, 4))\n",
    "for i in range(n):\n",
    "    # original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i + row * n].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # reconstructed\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed[i + row * n].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "fig.savefig('images/digits_0.9999999.png',bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
